{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Title: Exercice 6.2\n",
    "### Author: Jerock Kalala\n",
    "### Date: October 10th 2022\n",
    "### Professor: Dr. Brett Werner\n",
    "### Data Scaling and Working with Dataframes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Data Normalization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Build a Python function that takes in a vector (array) and normalizes it."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original Array =  [ 1  2  4  8 10 15]\n",
      "\n",
      "The array after normalization=  [0.0, 0.07142857142857142, 0.21428571428571427, 0.5, 0.6428571428571429, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# import module\n",
    "import numpy as np\n",
    "\n",
    "# explicit function to normalize array\n",
    "def normalize(arr):\n",
    "    norm_arr = []\n",
    "    for i in arr:\n",
    "        temp = (i - min(arr))/(np.max(arr) - np.min(arr))\n",
    "        norm_arr.append(temp)\n",
    "    return norm_arr\n",
    "\n",
    "\n",
    "# assign array\n",
    "array_1d = np.array([1, 2, 4, 8, 10, 15])\n",
    "\n",
    "print(\"The original Array = \", array_1d)\n",
    "print(\"\\nThe array after normalization= \", normalize( array_1d))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the The L1 norm of the array =  40.0\n",
      " the The L2 norm of the array =  20.248456731316587\n"
     ]
    }
   ],
   "source": [
    "print(\" the The L1 norm of the array = \", np.linalg.norm(array_1d, ord=1))\n",
    "print(\" the The L2 norm of the array = \", np.linalg.norm(array_1d, ord=2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04938648 0.09877296 0.19754592 0.39509184 0.4938648  0.7407972 ]]\n"
     ]
    }
   ],
   "source": [
    "#Or we can also use this:\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x_array = np.array([1, 2, 4, 8, 10, 15])\n",
    "normalized_arr = preprocessing.normalize([x_array])\n",
    "print(normalized_arr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Data Standardization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Build a Python function that takes in a vector (array) and standardizes it."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the sample is 6.666666666666667 \n",
      "Variance of the sample is 23.888888888888886 \n",
      "Standard Deviation of the sample is 4.887626099538393 \n"
     ]
    }
   ],
   "source": [
    "#function to calculate mean\n",
    "def mean(data):\n",
    "  n = len(data)\n",
    "  mean = sum(data) / n\n",
    "  return mean\n",
    "\n",
    "#Function to calculate variance. It will help us to calculate the standard deviation\n",
    "def variance(data):\n",
    "  n = len(data)\n",
    "  m = sum(data) / n\n",
    "  deviations = [(x - m) ** 2 for x in data]\n",
    "  variance = sum(deviations) / n\n",
    "  return variance\n",
    "\n",
    "#function to calculate the standard deviation\n",
    "def stdev(data):\n",
    "  import math\n",
    "  var = variance(data) #call variance function\n",
    "  std_dev = math.sqrt(var)\n",
    "  return std_dev\n",
    "\n",
    "print(\"Mean of the sample is % s \" % (mean(array_1d)))\n",
    "print(\"Variance of the sample is % s \"% (variance(array_1d)))\n",
    "print(\"Standard Deviation of the sample is % s \"% (stdev(array_1d)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standardized array is: \n"
     ]
    },
    {
     "data": {
      "text/plain": "[-1.159390377099805,\n -0.954792075258663,\n -0.5455954715763789,\n 0.2727977357881894,\n 0.6819943394704735,\n 1.7049858486761837]"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explicit function to standardize an array\n",
    "def standard(arr):\n",
    "    norm_arrA = []\n",
    "    for i in arr:\n",
    "        temp = (i - mean(arr))/stdev(arr)\n",
    "        norm_arrA.append(temp)\n",
    "    return norm_arrA\n",
    "\n",
    "\n",
    "print(\"The standardized array is: \")\n",
    "standard(array_1d)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Working with a Dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "       housing_median_age  total_bedrooms  households  median_income  \\\n0                      41           129.0         126         8.3252   \n1                      21          1106.0        1138         8.3014   \n2                      52           190.0         177         7.2574   \n3                      52           235.0         219         5.6431   \n4                      52           280.0         259         3.8462   \n...                   ...             ...         ...            ...   \n20635                  25           374.0         330         1.5603   \n20636                  18           150.0         114         2.5568   \n20637                  17           485.0         433         1.7000   \n20638                  18           409.0         349         1.8672   \n20639                  16           616.0         530         2.3886   \n\n       median_house_value  \n0                452600.0  \n1                358500.0  \n2                352100.0  \n3                341300.0  \n4                342200.0  \n...                   ...  \n20635             78100.0  \n20636             77100.0  \n20637             92300.0  \n20638             84700.0  \n20639             89400.0  \n\n[20640 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>housing_median_age</th>\n      <th>total_bedrooms</th>\n      <th>households</th>\n      <th>median_income</th>\n      <th>median_house_value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>41</td>\n      <td>129.0</td>\n      <td>126</td>\n      <td>8.3252</td>\n      <td>452600.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21</td>\n      <td>1106.0</td>\n      <td>1138</td>\n      <td>8.3014</td>\n      <td>358500.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>52</td>\n      <td>190.0</td>\n      <td>177</td>\n      <td>7.2574</td>\n      <td>352100.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>52</td>\n      <td>235.0</td>\n      <td>219</td>\n      <td>5.6431</td>\n      <td>341300.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>52</td>\n      <td>280.0</td>\n      <td>259</td>\n      <td>3.8462</td>\n      <td>342200.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20635</th>\n      <td>25</td>\n      <td>374.0</td>\n      <td>330</td>\n      <td>1.5603</td>\n      <td>78100.0</td>\n    </tr>\n    <tr>\n      <th>20636</th>\n      <td>18</td>\n      <td>150.0</td>\n      <td>114</td>\n      <td>2.5568</td>\n      <td>77100.0</td>\n    </tr>\n    <tr>\n      <th>20637</th>\n      <td>17</td>\n      <td>485.0</td>\n      <td>433</td>\n      <td>1.7000</td>\n      <td>92300.0</td>\n    </tr>\n    <tr>\n      <th>20638</th>\n      <td>18</td>\n      <td>409.0</td>\n      <td>349</td>\n      <td>1.8672</td>\n      <td>84700.0</td>\n    </tr>\n    <tr>\n      <th>20639</th>\n      <td>16</td>\n      <td>616.0</td>\n      <td>530</td>\n      <td>2.3886</td>\n      <td>89400.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>20640 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"E:\\Bellevue\\Fall_2022\\calif_housing_data.csv\")\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### (a) How many rows does this data set have?     ==>      20640 rows"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### (b) What is the target vector for your model?   ==>     median house value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### (c) Create a new feature by taking the total bedrooms divided by the number of households. What does this new feature represent?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "df['new_feature'] = df['total_bedrooms'] / df['households']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "   housing_median_age  total_bedrooms  households  median_income  \\\n0                  41           129.0         126         8.3252   \n1                  21          1106.0        1138         8.3014   \n2                  52           190.0         177         7.2574   \n3                  52           235.0         219         5.6431   \n4                  52           280.0         259         3.8462   \n\n   median_house_value  new_feature  \n0            452600.0     1.023810  \n1            358500.0     0.971880  \n2            352100.0     1.073446  \n3            341300.0     1.073059  \n4            342200.0     1.081081  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>housing_median_age</th>\n      <th>total_bedrooms</th>\n      <th>households</th>\n      <th>median_income</th>\n      <th>median_house_value</th>\n      <th>new_feature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>41</td>\n      <td>129.0</td>\n      <td>126</td>\n      <td>8.3252</td>\n      <td>452600.0</td>\n      <td>1.023810</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21</td>\n      <td>1106.0</td>\n      <td>1138</td>\n      <td>8.3014</td>\n      <td>358500.0</td>\n      <td>0.971880</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>52</td>\n      <td>190.0</td>\n      <td>177</td>\n      <td>7.2574</td>\n      <td>352100.0</td>\n      <td>1.073446</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>52</td>\n      <td>235.0</td>\n      <td>219</td>\n      <td>5.6431</td>\n      <td>341300.0</td>\n      <td>1.073059</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>52</td>\n      <td>280.0</td>\n      <td>259</td>\n      <td>3.8462</td>\n      <td>342200.0</td>\n      <td>1.081081</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### (d) Now, create a new data frame that has three features: the median age, median income, and the new feature created in part (c)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "   housing_median_age  median_income  new_feature\n0                  41         8.3252     1.023810\n1                  21         8.3014     0.971880\n2                  52         7.2574     1.073446\n3                  52         5.6431     1.073059\n4                  52         3.8462     1.081081",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>housing_median_age</th>\n      <th>median_income</th>\n      <th>new_feature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>41</td>\n      <td>8.3252</td>\n      <td>1.023810</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21</td>\n      <td>8.3014</td>\n      <td>0.971880</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>52</td>\n      <td>7.2574</td>\n      <td>1.073446</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>52</td>\n      <td>5.6431</td>\n      <td>1.073059</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>52</td>\n      <td>3.8462</td>\n      <td>1.081081</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df[['housing_median_age','median_income','new_feature']]\n",
    "new_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### (e) Take the data frame created in part (d) and apply data standardization to the features."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standardized array is: \n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.9821426581785085,\n -0.6070189133741599,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.061600736756142,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.6972653653772094,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.6972653653772094,\n 1.8561815225324763,\n 0.9026845796008751,\n 1.061600736756142,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 0.9821426581785085,\n 1.617807286799576,\n 1.8561815225324763,\n 1.6972653653772094,\n 1.8561815225324763,\n 1.617807286799576,\n 1.8561815225324763,\n 1.5383492082219425,\n 1.617807286799576,\n 1.7767234439548427,\n 1.617807286799576,\n 1.5383492082219425,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.7767234439548427,\n 1.617807286799576,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.6972653653772094,\n 1.1410588153337755,\n 0.9026845796008751,\n 0.9026845796008751,\n -0.6070189133741599,\n 1.1410588153337755,\n 0.9821426581785085,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n -2.116722406349195,\n 1.8561815225324763,\n 1.617807286799576,\n 1.6972653653772094,\n 1.8561815225324763,\n 1.5383492082219425,\n 1.8561815225324763,\n 1.5383492082219425,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.3794330510666757,\n -0.20972852048599275,\n 1.3794330510666757,\n 1.617807286799576,\n 1.3794330510666757,\n -0.6864769919517933,\n -0.9248512276846935,\n 0.5848522652903415,\n -0.7659350705294268,\n -0.448102756218893,\n 0.7437684224456084,\n -0.9248512276846935,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 0.5053941867127081,\n 1.8561815225324763,\n 0.9026845796008751,\n -1.4810577777281275,\n -1.4810577777281275,\n 1.8561815225324763,\n -1.004309306262327,\n 1.8561815225324763,\n 1.8561815225324763,\n -0.13027044190835935,\n 0.8232265010232418,\n 0.5848522652903415,\n 0.18756187240217437,\n 0.02864571524690751,\n -0.5275608347965265,\n 0.6643103438679749,\n 0.02864571524690751,\n -0.05081236333072591,\n 0.8232265010232418,\n 1.8561815225324763,\n 0.42593610813507465,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n -0.05081236333072591,\n 1.8561815225324763,\n 0.2670199509798078,\n -0.20972852048599275,\n 1.8561815225324763,\n 0.5053941867127081,\n 1.8561815225324763,\n -0.05081236333072591,\n 1.8561815225324763,\n 1.6972653653772094,\n 1.4588911296443092,\n 0.9821426581785085,\n 0.6643103438679749,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n -0.05081236333072591,\n 1.6972653653772094,\n 1.2205168939114088,\n 0.9026845796008751,\n 0.10810379382454094,\n 0.42593610813507465,\n -0.8453931491070601,\n 0.5053941867127081,\n 0.42593610813507465,\n -0.05081236333072591,\n -0.20972852048599275,\n 0.02864571524690751,\n 0.2670199509798078,\n 0.6643103438679749,\n 0.8232265010232418,\n 0.10810379382454094,\n 1.8561815225324763,\n 1.2999749724890424,\n 1.6972653653772094,\n 0.7437684224456084,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.3794330510666757,\n 1.061600736756142,\n 1.1410588153337755,\n 0.9821426581785085,\n 0.02864571524690751,\n -0.13027044190835935,\n 1.2999749724890424,\n 1.6972653653772094,\n 1.8561815225324763,\n 0.5848522652903415,\n 1.1410588153337755,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.4588911296443092,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.617807286799576,\n 1.8561815225324763,\n 1.7767234439548427,\n 1.6972653653772094,\n 1.8561815225324763,\n 1.1410588153337755,\n 1.8561815225324763,\n 0.10810379382454094,\n 0.8232265010232418,\n 1.4588911296443092,\n 1.8561815225324763,\n 1.1410588153337755,\n 1.7767234439548427,\n 0.8232265010232418,\n 1.8561815225324763,\n -0.6864769919517933,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.6972653653772094,\n 1.1410588153337755,\n 1.8561815225324763,\n 1.2205168939114088,\n 1.5383492082219425,\n 1.617807286799576,\n 0.6643103438679749,\n 0.10810379382454094,\n 0.9026845796008751,\n 1.2205168939114088,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.3794330510666757,\n 1.617807286799576,\n 0.7437684224456084,\n 0.02864571524690751,\n 1.4588911296443092,\n 0.42593610813507465,\n 0.5053941867127081,\n 0.8232265010232418,\n 0.8232265010232418,\n 1.1410588153337755,\n 1.8561815225324763,\n 1.8561815225324763,\n 0.9821426581785085,\n 1.5383492082219425,\n 1.5383492082219425,\n 1.3794330510666757,\n 1.6972653653772094,\n 0.9026845796008751,\n 1.3794330510666757,\n 1.8561815225324763,\n 1.2999749724890424,\n -0.05081236333072591,\n 0.5053941867127081,\n 1.617807286799576,\n 1.2205168939114088,\n 1.2999749724890424,\n 1.2999749724890424,\n 1.3794330510666757,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.617807286799576,\n 1.2205168939114088,\n 1.1410588153337755,\n 1.4588911296443092,\n 0.9026845796008751,\n 1.6972653653772094,\n 1.2205168939114088,\n 1.7767234439548427,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.617807286799576,\n 1.3794330510666757,\n 1.1410588153337755,\n 1.061600736756142,\n 0.8232265010232418,\n 0.9821426581785085,\n 1.8561815225324763,\n 0.8232265010232418,\n 1.6972653653772094,\n 1.1410588153337755,\n 1.2205168939114088,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 0.3464780295574412,\n 1.617807286799576,\n 1.8561815225324763,\n 1.2999749724890424,\n 0.8232265010232418,\n 0.9821426581785085,\n 1.3794330510666757,\n 1.4588911296443092,\n 1.6972653653772094,\n 0.6643103438679749,\n 0.42593610813507465,\n -0.448102756218893,\n -0.3686446776412596,\n -0.5275608347965265,\n 1.061600736756142,\n 0.10810379382454094,\n 1.1410588153337755,\n 1.6972653653772094,\n 1.617807286799576,\n 1.8561815225324763,\n 1.4588911296443092,\n 1.5383492082219425,\n 1.2999749724890424,\n 0.8232265010232418,\n 0.8232265010232418,\n 0.18756187240217437,\n 0.9821426581785085,\n 1.4588911296443092,\n 0.6643103438679749,\n 0.7437684224456084,\n 1.6972653653772094,\n 1.8561815225324763,\n 1.617807286799576,\n -0.13027044190835935,\n 1.061600736756142,\n 1.1410588153337755,\n 1.617807286799576,\n 1.8561815225324763,\n 1.7767234439548427,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.4588911296443092,\n 0.9821426581785085,\n 1.2999749724890424,\n 0.9821426581785085,\n 1.2999749724890424,\n 0.5848522652903415,\n 0.6643103438679749,\n 0.7437684224456084,\n -0.7659350705294268,\n -0.05081236333072591,\n -0.20972852048599275,\n 0.5848522652903415,\n 1.061600736756142,\n 1.2205168939114088,\n 1.1410588153337755,\n 1.2999749724890424,\n 1.061600736756142,\n 1.1410588153337755,\n 1.2205168939114088,\n 1.061600736756142,\n 0.9821426581785085,\n 1.4588911296443092,\n 1.1410588153337755,\n 1.1410588153337755,\n 0.5053941867127081,\n 1.3794330510666757,\n 1.3794330510666757,\n 1.3794330510666757,\n 1.2999749724890424,\n 1.3794330510666757,\n 0.7437684224456084,\n 1.2999749724890424,\n 0.5848522652903415,\n 1.1410588153337755,\n 0.5848522652903415,\n 0.3464780295574412,\n 1.1410588153337755,\n 0.9821426581785085,\n 1.2205168939114088,\n 1.5383492082219425,\n 1.2999749724890424,\n 0.7437684224456084,\n 1.4588911296443092,\n 0.9026845796008751,\n 1.3794330510666757,\n 0.5848522652903415,\n 0.8232265010232418,\n -0.13027044190835935,\n 0.42593610813507465,\n -0.20972852048599275,\n 0.3464780295574412,\n -0.05081236333072591,\n 0.5848522652903415,\n 0.3464780295574412,\n 0.10810379382454094,\n 0.5848522652903415,\n 0.9821426581785085,\n 1.3794330510666757,\n 0.9026845796008751,\n 1.2205168939114088,\n 0.9821426581785085,\n -0.3686446776412596,\n 1.2205168939114088,\n 1.1410588153337755,\n 1.617807286799576,\n 0.9026845796008751,\n 0.5053941867127081,\n 0.42593610813507465,\n 0.6643103438679749,\n 1.1410588153337755,\n 1.3794330510666757,\n 1.8561815225324763,\n 1.4588911296443092,\n 1.2205168939114088,\n 1.617807286799576,\n 1.8561815225324763,\n 1.8561815225324763,\n 0.7437684224456084,\n 1.8561815225324763,\n 1.3794330510666757,\n -1.0837673848399605,\n 0.5848522652903415,\n 1.8561815225324763,\n 1.061600736756142,\n 0.6643103438679749,\n 1.8561815225324763,\n 1.6972653653772094,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.061600736756142,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 0.6643103438679749,\n 0.9821426581785085,\n 1.8561815225324763,\n 1.8561815225324763,\n 0.6643103438679749,\n 1.061600736756142,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.2205168939114088,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.5383492082219425,\n 1.3794330510666757,\n 1.8561815225324763,\n 1.2999749724890424,\n 1.8561815225324763,\n -1.4810577777281275,\n 1.6972653653772094,\n 1.8561815225324763,\n 1.3794330510666757,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.617807286799576,\n 1.6972653653772094,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.3794330510666757,\n 1.3794330510666757,\n 1.8561815225324763,\n 0.10810379382454094,\n 0.6643103438679749,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 0.9821426581785085,\n 1.061600736756142,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 0.5053941867127081,\n 1.617807286799576,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.2205168939114088,\n 1.3794330510666757,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.6972653653772094,\n 1.8561815225324763,\n 1.617807286799576,\n 1.8561815225324763,\n 1.617807286799576,\n 1.8561815225324763,\n 1.8561815225324763,\n 0.9821426581785085,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 0.5053941867127081,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.5383492082219425,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.4588911296443092,\n 1.6972653653772094,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.4588911296443092,\n 1.8561815225324763,\n 1.2205168939114088,\n 1.5383492082219425,\n 0.5053941867127081,\n 1.8561815225324763,\n -1.1632254634175938,\n 1.8561815225324763,\n 0.8232265010232418,\n 1.061600736756142,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.2999749724890424,\n -1.2426835419952273,\n 0.10810379382454094,\n 1.061600736756142,\n 0.02864571524690751,\n 1.061600736756142,\n 1.8561815225324763,\n -0.13027044190835935,\n -0.8453931491070601,\n 1.6972653653772094,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.1410588153337755,\n 1.1410588153337755,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.6972653653772094,\n 1.2999749724890424,\n -0.13027044190835935,\n 1.8561815225324763,\n 1.617807286799576,\n 1.8561815225324763,\n -0.6070189133741599,\n -0.2891865990636262,\n -1.8783481706162946,\n 0.18756187240217437,\n 1.8561815225324763,\n -0.05081236333072591,\n -0.448102756218893,\n -0.6864769919517933,\n -1.3221416205728607,\n -1.8783481706162946,\n 0.5848522652903415,\n 0.9026845796008751,\n 0.5848522652903415,\n -0.20972852048599275,\n 0.18756187240217437,\n 0.2670199509798078,\n 0.5053941867127081,\n 0.5053941867127081,\n 0.10810379382454094,\n 0.5848522652903415,\n -0.2891865990636262,\n 0.10810379382454094,\n 0.18756187240217437,\n 0.18756187240217437,\n -0.13027044190835935,\n 0.10810379382454094,\n 0.7437684224456084,\n 0.7437684224456084,\n 0.2670199509798078,\n 0.8232265010232418,\n 0.6643103438679749,\n 0.3464780295574412,\n 0.2670199509798078,\n -0.2891865990636262,\n 0.3464780295574412,\n 0.02864571524690751,\n 0.5848522652903415,\n 0.18756187240217437,\n 1.1410588153337755,\n 1.061600736756142,\n 0.6643103438679749,\n -1.0837673848399605,\n -0.6864769919517933,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.7767234439548427,\n 1.617807286799576,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.2999749724890424,\n 1.3794330510666757,\n 1.617807286799576,\n 1.8561815225324763,\n 1.8561815225324763,\n 1.2999749724890424,\n 1.2999749724890424,\n 0.7437684224456084,\n 0.5848522652903415,\n 0.5053941867127081,\n 0.5848522652903415,\n 1.061600736756142,\n 1.3794330510666757,\n -1.8783481706162946,\n 0.7437684224456084,\n 1.1410588153337755,\n 0.6643103438679749,\n 0.5848522652903415,\n -1.4810577777281275,\n -0.05081236333072591,\n 0.18756187240217437,\n 1.4588911296443092,\n 0.02864571524690751,\n 1.8561815225324763,\n 0.7437684224456084,\n 1.1410588153337755,\n 0.3464780295574412,\n -0.20972852048599275,\n 0.5053941867127081,\n 0.5053941867127081,\n -0.2891865990636262,\n 0.8232265010232418,\n 1.2999749724890424,\n 1.2999749724890424,\n 1.2205168939114088,\n 1.2205168939114088,\n -0.8453931491070601,\n -0.13027044190835935,\n -0.8453931491070601,\n 1.1410588153337755,\n -0.7659350705294268,\n 0.5848522652903415,\n 0.5848522652903415,\n -0.9248512276846935,\n -0.6070189133741599,\n -0.9248512276846935,\n 0.5848522652903415,\n 0.5848522652903415,\n 0.7437684224456084,\n 0.7437684224456084,\n 0.5848522652903415,\n 0.5848522652903415,\n 0.5848522652903415,\n 0.5848522652903415,\n 0.5848522652903415,\n -0.3686446776412596,\n -1.004309306262327,\n -0.3686446776412596,\n -1.8783481706162946,\n 0.5848522652903415,\n 0.5848522652903415,\n 0.5053941867127081,\n 0.10810379382454094,\n 0.8232265010232418,\n 0.6643103438679749,\n -0.13027044190835935,\n 0.18756187240217437,\n 1.2205168939114088,\n 0.10810379382454094,\n 0.42593610813507465,\n 0.7437684224456084,\n 0.9821426581785085,\n -0.9248512276846935,\n 0.5053941867127081,\n -0.7659350705294268,\n -0.448102756218893,\n 0.02864571524690751,\n -0.7659350705294268,\n 0.9821426581785085,\n 0.6643103438679749,\n 1.061600736756142,\n -1.4810577777281275,\n -0.6864769919517933,\n 0.2670199509798078,\n -1.7988900920386612,\n -0.6070189133741599,\n -1.8783481706162946,\n -1.4810577777281275,\n -1.4810577777281275,\n -0.448102756218893,\n 0.5848522652903415,\n 0.10810379382454094,\n -0.20972852048599275,\n -0.20972852048599275,\n 0.02864571524690751,\n 1.5383492082219425,\n 0.9821426581785085,\n 1.1410588153337755,\n 0.02864571524690751,\n 0.9821426581785085,\n 1.1410588153337755,\n 0.6643103438679749,\n 0.6643103438679749,\n 0.6643103438679749,\n 0.7437684224456084,\n 0.42593610813507465,\n 0.18756187240217437,\n 0.5053941867127081,\n 0.9026845796008751,\n 0.6643103438679749,\n 0.5848522652903415,\n 1.2999749724890424,\n 1.2999749724890424,\n 1.2205168939114088,\n 1.1410588153337755,\n 0.5053941867127081,\n 0.42593610813507465,\n 0.5053941867127081,\n 0.5848522652903415,\n 0.7437684224456084,\n 0.6643103438679749,\n 0.6643103438679749,\n 0.9026845796008751,\n 0.3464780295574412,\n 1.061600736756142,\n 0.7437684224456084,\n 0.2670199509798078,\n 0.3464780295574412,\n 0.8232265010232418,\n 0.9026845796008751,\n 0.8232265010232418,\n 0.2670199509798078,\n -0.5275608347965265,\n -0.13027044190835935,\n -0.05081236333072591,\n 0.7437684224456084,\n 0.02864571524690751,\n -0.8453931491070601,\n -0.448102756218893,\n -0.05081236333072591,\n -0.6070189133741599,\n 0.3464780295574412,\n 0.18756187240217437,\n -0.9248512276846935,\n 0.5053941867127081,\n 0.6643103438679749,\n 0.6643103438679749,\n 0.5053941867127081,\n 0.3464780295574412,\n -0.13027044190835935,\n 0.5053941867127081,\n 0.5053941867127081,\n 0.42593610813507465,\n 0.02864571524690751,\n 0.5848522652903415,\n 0.5848522652903415,\n 0.5053941867127081,\n -0.2891865990636262,\n -0.05081236333072591,\n 0.18756187240217437,\n 0.5848522652903415,\n -0.20972852048599275,\n -0.8453931491070601,\n 0.5053941867127081,\n -0.7659350705294268,\n -0.8453931491070601,\n 0.18756187240217437,\n -1.6399739348833944,\n 0.9026845796008751,\n 0.42593610813507465,\n 0.2670199509798078,\n 0.02864571524690751,\n 0.5848522652903415,\n 0.5848522652903415,\n 0.5848522652903415,\n 0.5848522652903415,\n 0.10810379382454094,\n -0.448102756218893,\n 0.18756187240217437,\n 0.3464780295574412,\n 0.5848522652903415,\n -0.5275608347965265,\n -0.13027044190835935,\n -0.2891865990636262,\n 0.6643103438679749,\n -0.6864769919517933,\n 0.3464780295574412,\n 0.3464780295574412,\n 0.3464780295574412,\n 0.5053941867127081,\n 0.2670199509798078,\n 0.5053941867127081,\n 0.5053941867127081,\n 0.2670199509798078,\n 0.5053941867127081,\n 0.5848522652903415,\n 0.6643103438679749,\n 0.5848522652903415,\n 0.5053941867127081,\n 0.6643103438679749,\n -0.9248512276846935,\n 0.5053941867127081,\n -0.3686446776412596,\n -1.3221416205728607,\n -0.448102756218893,\n -1.004309306262327,\n 0.42593610813507465,\n 0.5053941867127081,\n 0.5848522652903415,\n 0.5053941867127081,\n -0.13027044190835935,\n -0.20972852048599275,\n -1.560515856305761,\n 0.5848522652903415,\n 0.18756187240217437,\n 0.2670199509798078,\n 0.2670199509798078,\n 0.3464780295574412,\n -0.9248512276846935,\n -0.5275608347965265,\n -1.7988900920386612,\n -0.9248512276846935,\n -0.8453931491070601,\n -1.004309306262327,\n -1.2426835419952273,\n -1.0837673848399605,\n -1.004309306262327,\n -1.004309306262327,\n -1.004309306262327,\n -1.0837673848399605,\n -1.004309306262327,\n -1.1632254634175938,\n -1.0837673848399605,\n -0.3686446776412596,\n -0.8453931491070601,\n -1.004309306262327,\n -2.116722406349195,\n -1.0837673848399605,\n -0.9248512276846935,\n 0.5848522652903415,\n -1.4810577777281275,\n -0.6070189133741599,\n -1.0837673848399605,\n -0.6864769919517933,\n 0.18756187240217437,\n -1.7988900920386612,\n -1.1632254634175938,\n -1.1632254634175938,\n -1.3221416205728607,\n -1.6399739348833944,\n -1.0837673848399605,\n -1.7194320134610277,\n -1.8783481706162946,\n -2.0372643277715614,\n -0.448102756218893,\n 0.5053941867127081,\n 0.18756187240217437,\n -0.3686446776412596,\n -1.7988900920386612,\n -0.20972852048599275,\n 0.3464780295574412,\n -0.3686446776412596,\n -0.8453931491070601,\n -0.6864769919517933,\n -1.957806249193928,\n -1.2426835419952273,\n 0.18756187240217437,\n -0.9248512276846935,\n -0.9248512276846935,\n -1.004309306262327,\n -1.0837673848399605,\n -0.6070189133741599,\n -0.2891865990636262,\n -0.13027044190835935,\n 0.3464780295574412,\n 0.02864571524690751,\n 0.18756187240217437,\n -1.1632254634175938,\n -0.448102756218893,\n -0.05081236333072591,\n -0.8453931491070601,\n -0.05081236333072591,\n 0.5053941867127081,\n -0.20972852048599275,\n -0.05081236333072591,\n -0.20972852048599275,\n -0.20972852048599275,\n -0.8453931491070601,\n -0.05081236333072591,\n -0.05081236333072591,\n 0.02864571524690751,\n 0.42593610813507465,\n -0.13027044190835935,\n 0.2670199509798078,\n -0.20972852048599275,\n -0.13027044190835935,\n -0.2891865990636262,\n -0.20972852048599275,\n -0.2891865990636262,\n -0.448102756218893,\n 0.3464780295574412,\n -0.5275608347965265,\n -0.20972852048599275,\n -0.13027044190835935,\n -1.7194320134610277,\n -1.560515856305761,\n -1.4810577777281275,\n -0.448102756218893,\n -0.20972852048599275,\n -1.2426835419952273,\n -0.5275608347965265,\n -0.20972852048599275,\n -0.448102756218893,\n -0.20972852048599275,\n -0.2891865990636262,\n -0.448102756218893,\n -0.2891865990636262,\n -0.9248512276846935,\n -0.6864769919517933,\n 0.5053941867127081,\n -1.7988900920386612,\n 0.42593610813507465,\n 0.18756187240217437,\n -1.004309306262327,\n -0.8453931491070601,\n -0.7659350705294268,\n -0.6070189133741599,\n -1.7194320134610277,\n -1.957806249193928,\n -0.5275608347965265,\n -0.2891865990636262,\n -0.20972852048599275,\n -0.20972852048599275,\n -0.20972852048599275,\n -1.0837673848399605,\n -1.7988900920386612,\n 1.3794330510666757,\n -0.3686446776412596,\n -1.2426835419952273,\n -0.8453931491070601,\n -0.448102756218893,\n -2.0372643277715614,\n -0.448102756218893,\n -0.6864769919517933,\n -0.8453931491070601,\n -0.8453931491070601,\n -1.3221416205728607,\n -0.448102756218893,\n -0.5275608347965265,\n -1.004309306262327,\n -0.2891865990636262,\n -0.6864769919517933,\n -0.7659350705294268,\n -1.0837673848399605,\n -1.7194320134610277,\n 0.02864571524690751,\n 0.8232265010232418,\n 1.8561815225324763,\n -2.0372643277715614,\n -0.6864769919517933,\n -1.2426835419952273,\n -1.4810577777281275,\n -0.05081236333072591,\n -1.957806249193928,\n -1.1632254634175938,\n -0.5275608347965265,\n -0.13027044190835935,\n -1.2426835419952273,\n 1.1410588153337755,\n 1.4588911296443092,\n -1.2426835419952273,\n -1.957806249193928,\n -1.004309306262327,\n -0.20972852048599275,\n 0.2670199509798078,\n -0.9248512276846935,\n -1.3221416205728607,\n -1.4015996991504942,\n -0.2891865990636262,\n -0.5275608347965265,\n -0.9248512276846935,\n -1.3221416205728607,\n ...]"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The standardized median age feature is: \")\n",
    "`standard(new_df['housing_median_age'])`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standardized median income feature is: \n"
     ]
    },
    {
     "data": {
      "text/plain": "[2.344765758301686,\n 2.3322379635373007,\n 1.7826994032844703,\n 0.9329675088245615,\n -0.012880995886464651,\n 0.0874466378148665,\n -0.11136630682832735,\n -0.3951366495795735,\n -0.9423591469347871,\n -0.09446957523434674,\n -0.35139464349048327,\n -0.3159167709224365,\n -0.4188236564870231,\n -0.6301117581014737,\n -1.028527214284776,\n -0.9188826911998481,\n -0.5767370358700206,\n -0.921409305269976,\n -0.9893646961977925,\n -0.6671161266702227,\n -1.3227198400753,\n -1.135487209920193,\n -1.1294338637105112,\n -0.8896160782208659,\n -0.6688531738434356,\n -0.7721285239599159,\n -0.7427039976015506,\n -1.0857444954145488,\n -1.172912680833963,\n -1.1491730361333858,\n -1.0228949704201156,\n -1.0049454829635815,\n -1.0915872904517196,\n -1.3136661396573415,\n -0.600266129398087,\n -1.2551855514925048,\n -1.459893928965997,\n -1.2950849986832753,\n -0.20564059431997678,\n -0.6742222287424576,\n -0.9332001709305733,\n -1.3609348778859855,\n -1.4978984156041717,\n 0.049284237797308686,\n -0.4517222771918142,\n -0.6284273487213883,\n -0.9709941063962373,\n -1.124275359984,\n -1.537060933691155,\n -1.1031149671466784,\n -1.5522206181119227,\n -1.2455001975570141,\n -1.4527351891006344,\n -1.3807793258951153,\n -1.1900726013935823,\n -1.2945586207519988,\n -1.2448685440394822,\n -1.607279749723461,\n -1.3967812150059256,\n -0.6885923462663103,\n -0.25148811213417366,\n 1.1831023017672293,\n -1.5631166412893496,\n -1.4105196790122465,\n -0.672116717017351,\n -1.4233106627422691,\n -1.6133857337262703,\n -0.6639052212894351,\n -1.0627944176108863,\n -1.521480146925366,\n -1.104746738733636,\n -1.653916834434573,\n -1.1162744154285948,\n -1.7742994673175445,\n -0.7304393918028046,\n -1.5510099488699864,\n -0.7497048240875303,\n -1.4525772757212514,\n -1.6149648675201005,\n -0.9786792241928763,\n -1.2478688982477593,\n -1.4233106627422691,\n -1.2369202372772048,\n -1.6123856156568448,\n -1.0853233930695274,\n -0.7697598232691709,\n -1.5231645563054512,\n -1.6373885673924862,\n -1.5256911703755793,\n -1.3829374754133494,\n -0.9353056826556799,\n -1.581171404332139,\n -1.6426523467052525,\n -0.6502193950762418,\n -1.0648472915428655,\n -0.9796267044691745,\n -0.5454175489590595,\n -0.9814163894355149,\n -1.3960442859021385,\n -0.6633788433581584,\n -0.7261230927663359,\n -0.3437095256938442,\n -0.3925047599231903,\n -0.6796439214346072,\n -0.5422066435782719,\n 0.557923232789943,\n -0.314758739473628,\n -0.36929149315388976,\n 0.015438136816219458,\n 0.01875431778326239,\n 0.6427227175186128,\n -0.646271560591667,\n -0.44603739553402644,\n -0.3801875163313165,\n -0.20974634218393473,\n -0.38308259495333813,\n -0.7618115165068934,\n -0.4110859008972563,\n 1.0469283309459583,\n 0.7454190519106888,\n 1.0976711635210281,\n 0.5756621690739663,\n 1.3015899740976051,\n 0.6877806684358944,\n 1.7711190887963841,\n 0.8350085758139756,\n 1.9103986894121876,\n 1.131043524363968,\n 1.939033648873638,\n 1.1558885627202264,\n 1.6760552344078197,\n 4.069443050129655,\n 1.904187429823123,\n 1.5933086236111287,\n 2.281442493169104,\n 2.384665205492456,\n 1.570253270221211,\n 2.340449459265217,\n 1.6564213375712002,\n 1.2946417854047532,\n 1.3115911547918617,\n 1.6761078722009473,\n 1.534091106342505,\n -0.5146770777725026,\n -0.41556011331310794,\n 0.7208898403131961,\n 1.3954431592442333,\n -0.3197593298207562,\n -0.4426159389807282,\n 0.353793871040855,\n 0.10597514099580468,\n 0.7791598773055224,\n -0.37392361894912435,\n 0.47380803937193333,\n 2.2559131635021856,\n 2.636431770022082,\n 1.5730430732569776,\n 1.1367284060217557,\n 1.914609712862401,\n -0.5911071533938733,\n -0.882352062769248,\n -0.45045897015675035,\n -0.10299689772102859,\n -0.33986696679552447,\n -0.49277975583139366,\n -0.909460526229996,\n -1.188861932151646,\n -1.3042439746874892,\n -0.8176602150153468,\n -1.1019569356978698,\n -0.6447450645909647,\n -0.8894055270483552,\n -0.8634550950364159,\n -1.1687016573837496,\n -0.8427158045441158,\n -0.9024070619508887,\n -0.913724187473337,\n -0.6534829382501572,\n -0.7829192715510873,\n -0.4809362523776689,\n -0.7089631722067169,\n -1.0175785533142214,\n -1.0358438675295214,\n -0.8530854497902659,\n -0.7778660434108314,\n -0.8837732831836951,\n -0.4921481023138615,\n -1.0450028435337353,\n -0.8984592274663137,\n -0.9188826911998481,\n -0.26091027710402587,\n -0.8508746624789039,\n -0.9320421394817645,\n -1.1952311051200935,\n -0.1293157942848614,\n -1.146330595304492,\n -1.1704387045569629,\n -0.6741169531562022,\n -0.6846445117817355,\n -0.646271560591667,\n -0.4447740884989624,\n -1.2538696066643131,\n -1.019526151659945,\n -1.256080393975675,\n -1.1947573649819443,\n -0.9649407601865556,\n -0.8304511987453695,\n -0.9060390696766977,\n -1.1848088220808157,\n -1.3383532646342167,\n -0.18690153996652772,\n 0.017964750886347372,\n -0.4112964520697669,\n -0.6666423865320736,\n -0.7214909669711014,\n -0.5652093591750618,\n -0.5466808559941233,\n -0.4802519610670092,\n -0.5443647930965061,\n -0.5240992427423548,\n -0.42240302641970445,\n -0.4184551919351296,\n 0.5712405944512423,\n 0.4744923306825928,\n -0.20242968893918917,\n 0.6567770082836996,\n 0.11950305382961458,\n 0.45970111081371856,\n 0.21161919180303007,\n -0.4665134970606884,\n 0.15961305219289593,\n -0.011565051058273036,\n 0.07407663836043922,\n 0.4135377662407557,\n -0.49530636990152155,\n -0.824871592673837,\n -0.6337437658272825,\n -0.658851993149179,\n -0.765338248646447,\n -0.5747367997311692,\n -0.5976868775348316,\n -1.0651104805085037,\n -0.6381653404500064,\n -0.4300881442163437,\n -0.7790767126527678,\n -1.1326974068844267,\n -0.6556937255615192,\n -0.5627880206911892,\n -1.128065281089192,\n -0.9425170603141702,\n -0.7272811242151447,\n -1.1138530769447221,\n 0.11566049493129506,\n -0.6285852621007714,\n -0.756337186021616,\n -0.8105014751499842,\n -0.8476111193049886,\n -1.0879026449327829,\n -0.8498219066163505,\n -0.9550974928716821,\n -0.1741631940296326,\n -0.39687369675278666,\n -0.7003832119269076,\n -0.5119925503229915,\n -0.8201868290854748,\n -0.5240992427423548,\n -0.2627525998634941,\n -0.18911232727788968,\n 0.23256903346784086,\n -0.3424988564519077,\n 0.0022786885343030598,\n 0.7169946436217491,\n -0.07604634763966364,\n 0.3782704448452196,\n 0.7301540919036652,\n 1.6932677927605664,\n 0.05291624552311757,\n -0.4838839687928181,\n -0.6337437658272825,\n 0.8284814894661453,\n 1.2702178493935166,\n 1.5170364613691412,\n 1.6846878324807568,\n 1.1128834857349232,\n -0.09641717358007028,\n -0.5240992427423548,\n -0.23696008123093787,\n -0.3012308266398178,\n 0.0022786885343030598,\n 0.1601920679173003,\n 0.26546765417263196,\n 0.47380803937193333,\n -0.15621370657309858,\n -0.40787499551646866,\n -0.2499616161334714,\n -1.0525826857441192,\n -1.018578671383647,\n -0.8877211176682699,\n -0.8311354900560292,\n -0.7566003749872545,\n -1.0121042228289443,\n 0.01875431778326239,\n -1.0685319370618018,\n -0.9433066272110852,\n -0.5569978634471459,\n -1.041897213739203,\n -1.1396455955772784,\n -0.8389785212320514,\n -0.3239703532709695,\n -0.9554133196304481,\n -0.7394404544276355,\n -1.1162744154285948,\n -0.9599928076325551,\n -0.607845971608471,\n -1.4014133408011604,\n -1.0241582774551796,\n -1.2052849236074776,\n -1.2954008254420415,\n -1.6330196305628897,\n -1.3429327526363237,\n -1.6157017966238876,\n -1.0121042228289443,\n -1.418152159015758,\n -0.8027637195602173,\n -0.9037230067790804,\n -0.7141743137263559,\n -1.3728836569259653,\n -0.5076236134933955,\n -0.7113845106905895,\n -0.9261993444445936,\n -0.745177973878551,\n -0.7726549018911926,\n -0.9057232429179317,\n -0.7332818326316987,\n -0.9011437549158247,\n -1.0669001654748442,\n -0.4426159389807282,\n -0.8530854497902659,\n -0.8548224969634788,\n 0.09276305492076051,\n -1.3399850362211743,\n -1.184914097667071,\n -0.893563912705441,\n -1.028527214284776,\n -0.9483598553513409,\n -1.1362767768171078,\n -0.6885923462663103,\n -0.9941020975792825,\n -0.7192275418666116,\n -0.8119753333575589,\n -1.2807675189525503,\n -0.7150691562095262,\n -1.214970277542968,\n -0.3747658236391669,\n -1.0675318189923761,\n 0.4205385927267353,\n -0.7426513598084231,\n 1.1602574995498227,\n 0.505180164076022,\n 0.8945419198413658,\n 0.7892136957929066,\n 1.5735168133951267,\n 2.011621165596689,\n 0.08455155919284461,\n 1.5589361446987633,\n 0.5812944129386265,\n 0.7840551920663952,\n 0.5944538612205431,\n -0.49778034617852196,\n 0.010858648814112689,\n -0.33986696679552447,\n -0.38155609895263587,\n -0.7020149835138652,\n -0.6915927004745873,\n -0.19074409886484725,\n -0.29380889780881697,\n -1.0775856374797603,\n -0.034725680034445996,\n -0.8311354900560292,\n -0.7234912031099527,\n 0.09002588967812172,\n -0.2033245314223595,\n 0.14482183232402218,\n -0.6556937255615192,\n -0.9727311535694502,\n -0.2828602368382625,\n 0.7723696019920535,\n -0.20921996425265812,\n -0.1885333115534853,\n -0.385925035782232,\n -0.5616826270355082,\n 0.3746384371194107,\n -0.4473533403622181,\n 0.11413399893059303,\n 0.34537182414042844,\n -1.122854139569553,\n -0.36381716266861247,\n -0.0018270593296548863,\n 0.6826221647093835,\n 0.6837275583650643,\n 0.20567112117960368,\n 0.6234572852338871,\n 0.9222820368196455,\n 2.113791122057488,\n 2.150216474901833,\n 1.2124215525393396,\n 1.6163639770010465,\n 2.612692125321504,\n 1.7395364129197843,\n 3.2697696969341563,\n 0.5461850049224733,\n 1.0109240804466346,\n 0.3782704448452196,\n 0.8140060963560368,\n 0.13387317135346752,\n 1.7872262534934498,\n 0.804426018006802,\n 2.0859983672860807,\n 1.2046837969495725,\n 1.3213817843136075,\n 1.480242643972903,\n 1.930664239766339,\n 1.4965603598424793,\n 1.2484784408317902,\n 1.0144508125861884,\n 0.21614604201200907,\n -0.17316307596020694,\n -0.4513538126399207,\n 0.1432953363233197,\n 0.1687193904039824,\n 0.024228648268539727,\n 0.010016444124069896,\n -0.40224275165180845,\n -0.4621971980242198,\n -0.16563587154295076,\n -1.2610283465296757,\n -1.14411980799313,\n -0.8949324953267601,\n -0.589896484151937,\n -0.6855919920580333,\n -0.5109397944604384,\n -0.8684556853835442,\n -0.334919014241524,\n -0.18690153996652772,\n -0.9949443022693252,\n -0.6328489233441121,\n 0.0022786885343030598,\n -0.4551437337451127,\n -0.698856715926205,\n -0.5279944394338021,\n -0.8842996611149716,\n -1.1016411089391036,\n -0.7109634083455683,\n 0.21483009718381768,\n -0.48777916548426536,\n -1.1294338637105112,\n 0.7149417696897702,\n -0.6919085272333533,\n -1.5379031383811979,\n -1.421784166741567,\n -1.299875037857893,\n -1.4132042064617574,\n -1.1181693759811908,\n -0.5190460146020989,\n -0.5966341216722781,\n -0.005932807193612832,\n -0.1622144149896525,\n -0.8379257653694981,\n -0.7020149835138652,\n -0.708331518689185,\n -0.9875223734383243,\n -0.5523130998587835,\n -0.6601679379773708,\n -1.0118936716564335,\n -1.0201051673843493,\n -0.9953127668212188,\n -0.765338248646447,\n -0.6995410072368647,\n -0.25269878137610996,\n -0.6871711258518634,\n -0.8349254111612212,\n -0.6651158905313714,\n -0.3793453116412739,\n -0.6207422309247492,\n -1.0664264253366953,\n -1.1790713026299,\n -0.508623731562821,\n -0.4896214882437336,\n -0.25338307268676963,\n -0.43635204159853586,\n 1.6944258242093748,\n 0.6188251594386521,\n -1.1082734708731896,\n 2.095736359014699,\n 2.9083586093196026,\n 0.7941616483469073,\n -0.32044362113141595,\n -0.6133729398868759,\n -0.8567174575160748,\n -1.0358438675295214,\n -1.2048638212624563,\n -0.8351359623337318,\n -1.3118238168978733,\n -0.5099923141841403,\n -1.126801974054128,\n -0.8465057256493076,\n -0.8738247402825663,\n -0.6163732940951528,\n 0.06902341022018339,\n 2.108948445089743,\n 4.205564383157799,\n 5.068139899140857,\n 4.391638981864097,\n 2.2721256037855073,\n 4.4793335452147875,\n 1.0654568341268964,\n 2.2364371800449496,\n 2.5671604342660737,\n 1.202420371845083,\n 1.059245574537832,\n 0.7064670849962157,\n 0.4464363869455468,\n 0.7478930281876889,\n -0.6472190408679651,\n -0.28912413422045463,\n -0.12052528283254112,\n -0.44982731663921843,\n -0.3650804697036765,\n -0.21980016067131883,\n 0.2311478130533939,\n -0.2773332685598576,\n -0.49972794452424546,\n -0.6264271125825369,\n -0.05256989190472472,\n 0.038809316964903064,\n 0.731364761145602,\n -0.6981197868224178,\n -0.6453240803153691,\n -0.68138096860782,\n -1.0148413880715828,\n -0.4747249927886043,\n -0.06351855287527916,\n 0.6840433851238304,\n -0.7141743137263559,\n -0.47240892989098704,\n 0.8753817631428952,\n 0.15582313108770393,\n -0.6101620345060883,\n -0.286229055598433,\n -0.3169695267849899,\n 0.47749268489086977,\n 0.18703734241240993,\n -0.270332442073878,\n -0.46361841843866675,\n -0.5240992427423548,\n -0.7803400196878318,\n -0.4714614496146889,\n 0.649144528280188,\n 0.14482183232402218,\n -0.20764083045882809,\n -0.62500589216809,\n 0.9892373096780365,\n 0.04870522207290431,\n 0.5675559489323059,\n 0.526603745878982,\n -0.4205080658671084,\n -0.10462866930798617,\n 0.3888506412638805,\n 0.34247674551840707,\n 0.3082095421922965,\n 1.9688266397838965,\n -0.3167589756124793,\n -0.15984571429890745,\n -0.09641717358007028,\n 0.4731237480612734,\n -0.3545002732850156,\n 1.7858576708721303,\n 1.677107990270373,\n 0.4023259163045629,\n 0.7531568075004553,\n 0.5839789403881377,\n 0.8489049531996793,\n 1.219264465645936,\n 0.9204923518533048,\n 0.8386405835397845,\n 0.6733052753257864,\n 1.0356638432166374,\n 0.41022158527371305,\n 0.26909966189844087,\n -0.07815185936477027,\n 0.7447347606000289,\n 0.24572848174975748,\n 0.7066249983755988,\n 1.1234636821535842,\n 0.6217728758538016,\n 0.5016534319364682,\n 0.7258904306603244,\n 0.13387317135346752,\n 0.3841658776755184,\n -0.18526976837957015,\n -0.4583020013327725,\n -0.19858713004086964,\n -0.46561865457751805,\n -0.7024360858588864,\n -0.2992832282940943,\n -0.4075591687577027,\n -0.5366270375067392,\n -0.275227756834751,\n -0.7763395474101292,\n -0.17958488672178216,\n 0.4910732355178077,\n -0.010354381816336739,\n 0.10292214899440016,\n 0.38611347602124174,\n -0.8794043463540987,\n 0.12934632114448805,\n 0.04175703338005249,\n 0.5489221701651121,\n -0.5448911710277826,\n -0.3267075185136081,\n -0.5477336118566768,\n -0.08146804033181321,\n -0.6885923462663103,\n -0.034725680034445996,\n -0.26091027710402587,\n -0.3298657861012679,\n 0.08218285850209957,\n -0.25269878137610996,\n 0.8819088494907259,\n -0.26301578882913246,\n -0.1786374064454843,\n -0.1093134328963485,\n -0.5240992427423548,\n 0.07870876415567377,\n 0.36037359518181333,\n -0.21390472784102021,\n -0.2777017331117511,\n -0.8847734012531207,\n -0.5058339285270548,\n -0.26091027710402587,\n -0.5569978634471459,\n 0.5944538612205431,\n -0.4228767665578535,\n -0.030619932170488053,\n 1.599625158786449,\n 2.1272663970981704,\n -0.016513003612273543,\n 0.06807592994388528,\n 1.3890213484826581,\n -0.18690153996652772,\n -0.46725042616447565,\n -0.1824799653438038,\n -0.40024251551295714,\n -0.15400291926173662,\n -0.3697652332920386,\n -0.6635367567375413,\n -0.0934168193717933,\n -0.2170629954286803,\n 0.01712254619630481,\n 0.07902459091443996,\n -0.16632016285361045,\n 0.3764807598788789,\n -0.651956442249455,\n -0.2503827184784927,\n 0.05238986759184097,\n 0.5967172863250326,\n 0.3133154081256804,\n -0.10957662186198668,\n 0.008279396950856999,\n -0.2170629954286803,\n -0.04704292362631984,\n -0.46267093816236887,\n 0.29836627487742307,\n 0.06807592994388528,\n -0.7810243109984916,\n 0.4685968978522944,\n 0.8501682602347436,\n 0.2771006064538461,\n 0.07381344939480104,\n 0.2714683625891859,\n 0.21761990021958355,\n 0.6635146458040405,\n -0.4605127886441345,\n -0.12331508586830744,\n -0.565946288278849,\n -0.4842524333447118,\n -0.22801165639923474,\n -0.5240992427423548,\n -0.44014196270372785,\n -0.6272693172725797,\n -0.46240774919673044,\n 0.12292451038291283,\n -0.6776436852957559,\n -0.9029860776752932,\n -0.8123437979094525,\n -0.7632853747144681,\n 0.01875431778326239,\n -0.6444292378321987,\n -0.21390472784102021,\n -0.7755499805132142,\n 1.3840207581355297,\n 1.1510458857524812,\n 0.013227349504857506,\n 0.479335007650338,\n -0.30938968457460597,\n 0.7612630276421162,\n 1.256584660973451,\n 0.6839907473307024,\n -0.3267075185136081,\n -0.36376452487548466,\n -0.7638117526457447,\n -0.6392180963125599,\n -1.5301653827914308,\n -0.8079748610798563,\n -0.18911232727788968,\n -0.29380889780881697,\n -0.7719179727874053,\n -0.5466282182009958,\n -0.7132794712431856,\n -0.2460664194420241,\n -0.7030677393764183,\n -0.6808545906765435,\n -0.407664444343958,\n -0.48125207913643486,\n -0.3925047599231903,\n -0.48462089789660534,\n 0.2680995438290152,\n 0.09002588967812172,\n -0.037199656311446366,\n -0.2035877203879977,\n 0.09902695230295262,\n 0.17198293357789754,\n -0.1424752425667778,\n 0.2086188375947531,\n 0.1936697043464958,\n 0.8995951479816215,\n 0.10397490485695336,\n -0.3670280680494001,\n 0.4856515428256581,\n 0.49575799910616974,\n -0.0016165081571442464,\n 0.03623006510164737,\n -0.3301816128600341,\n -0.41003314503470306,\n -0.42435062476542823,\n -0.6152152626463441,\n -0.3996108619954252,\n -0.20974634218393473,\n -0.867718756279757,\n 1.178943916110144,\n 0.2119350185617958,\n -0.3285498412730763,\n -0.33107645534320446,\n 0.0022786885343030598,\n 1.1472033268541613,\n 1.554198743317273,\n 1.305116706237159,\n -0.631006600584644,\n 0.0022786885343030598,\n -0.6885923462663103,\n -0.44987995443234596,\n -0.5796847522851698,\n -0.09941752778834725,\n -0.9119345025069963,\n -0.07388819812142923,\n 0.0022786885343030598,\n -0.43256212049334386,\n -0.552892115583188,\n 0.27320540976239904,\n 0.4440676862548018,\n 0.42996075769658754,\n -0.34823637590282347,\n 0.21282986104496637,\n 0.1366103365961063,\n -0.4109279875178734,\n 0.35321485531645064,\n 0.4173276873459477,\n 0.30110344012006185,\n 0.34721414689989716,\n -0.7872882083806837,\n -0.02819859368661546,\n 0.3460561154510884,\n 0.2499921429930983,\n -0.20242968893918917,\n 0.7161524389317065,\n -0.10520768503239054,\n 0.008858412675261376,\n 0.024228648268539727,\n 0.01875431778326239,\n -0.04272662458985125,\n -0.037199656311446366,\n 0.9791834911906523,\n 0.12813565190255174,\n 0.7438399181168587,\n -0.27517511904162323,\n -0.3835563350914872,\n -0.05751784445872522,\n 0.19967041276304973,\n 0.03322971089337064,\n -0.7131741956569302,\n -0.7315974232516133,\n 0.4409094186671422,\n 0.15503356419078893,\n -0.1666359896123764,\n -0.035304695758850375,\n -0.023566467891380914,\n -0.33560330555218365,\n 0.4422780012884611,\n 0.19798600338296463,\n 1.3292774532827574,\n -0.030619932170488053,\n -0.30791582636703146,\n 0.01170085350415525,\n -0.07604634763966364,\n 0.0746556540848436,\n 0.15856029633034274,\n 0.21846210490962656,\n -0.11836713331430694,\n -0.6227951048567281,\n -0.07446721384583362,\n 0.37932320070777326,\n -0.004301035606655256,\n -0.2682269303487714,\n -0.5124662904611406,\n 0.08523585050350455,\n 0.10397490485695336,\n 0.7862659793777571,\n 0.4375405999069715,\n 0.9313357372376039,\n -0.04083166403725526,\n 0.40801079796235107,\n -0.09299571702677203,\n -0.6414815214170494,\n -0.1951130356944436,\n -0.332708226930162,\n 0.6455125205543791,\n 0.27204737831359027,\n 0.39706213699179643,\n 0.6158248052303756,\n 1.052613212603746,\n 0.7642633818503931,\n 0.19177474379390003,\n 0.5023377232471281,\n 0.869117865760703,\n 1.3901267421383388,\n 1.1556253737545878,\n 1.124726989188648,\n 0.39500926305981754,\n 0.7128888957577909,\n 0.7748962160621816,\n -0.06551878901413048,\n 0.3692167444272611,\n -0.09389055950994236,\n 0.4252759941082254,\n -0.5240992427423548,\n -0.2679111035900054,\n 0.9933956953351222,\n -0.4737775125123062,\n 0.016596168265028213,\n 0.3915878065065193,\n 0.9730248693947153,\n -0.09868059868456001,\n 1.229949937650852,\n 1.023504513004147,\n 1.0325055756289778,\n 0.9248612886829012,\n 0.7459980676350927,\n 1.416393000909044,\n 0.9501800671773083,\n 1.175943561901867,\n -0.1575296514012902,\n 1.1642053340343974,\n 0.25725615844471605,\n 0.8964368803939615,\n 0.5398158319540262,\n 0.4353824503887371,\n 0.292260290874614,\n -0.29996751960475376,\n 0.36742705946092047,\n -0.02777749134159418,\n 0.5944538612205431,\n 0.24667596202605513,\n 0.14108454901195774,\n 0.4919154402078502,\n 0.40227327851143535,\n -0.3698705088782939,\n -0.38850428764548767,\n -0.507044597768991,\n 2.383928276388669,\n 1.4618194163782199,\n 1.4519235112702185,\n 1.2355295437223848,\n 0.9950274669220798,\n 0.4176435141047139,\n 1.520826382474333,\n 0.06328589076926765,\n 0.22362060863613747,\n 0.5741883108663918,\n -0.6584308908041577,\n 0.4436465839097805,\n 0.46285937840137864,\n 0.8207437338763782,\n 0.38390268870987976,\n 0.17056171316345062,\n 0.7986884985558863,\n 0.038809316964903064,\n 0.7672637360586696,\n 0.5103913055956608,\n 0.679516534914851,\n 0.5506065795451973,\n 0.15182265881000132,\n 0.5944538612205431,\n 1.0326634890083606,\n 0.9659187673224806,\n 0.6167196477135457,\n 0.34795107600368413,\n 0.8239020014640384,\n 0.6378274027577396,\n 0.7159418877591959,\n 0.2842593463192088,\n 0.7205740135544304,\n 0.46170134695256987,\n 2.386507528251925,\n 3.078641870087602,\n 0.6809377553292979,\n 0.795161766416333,\n 1.1670477748632913,\n 1.57772783684534,\n 1.6429987003236455,\n 0.5480273276819421,\n 0.29741879460112497,\n 0.566240004104114,\n 0.7461559810144758,\n 0.6639883859421898,\n 0.050547544832372525,\n -0.3690283041882514,\n 0.6385643318615271,\n 0.5004427626945318,\n 0.1420846670813834,\n -0.07067729274064162,\n -0.1766898080997605,\n 0.6333531903418881,\n -0.3235492509259482,\n 1.155941200513354,\n 0.9667083342193956,\n 0.5874530347345635,\n 0.6700943699449988,\n 0.7771070033735435,\n 0.9751830189129497,\n 0.31531564426453124,\n 0.5474483119575377,\n 0.18814273606809115,\n 0.6019810656377995,\n 1.778488379834257,\n 0.6684625983580412,\n 2.3492399707175373,\n 1.8135451500572826,\n 1.3837049313767635,\n 1.7635918843791276,\n 0.28320659045665514,\n 1.0863540379985797,\n 1.2140006863331692,\n 1.0245046310735726,\n 1.2856933605730503,\n 1.2983790687168175,\n 1.822493574888986,\n 1.2744288728437299,\n 1.3952852458648501,\n 1.3589651686067608,\n 1.1526250195463108,\n 1.3990225291769147,\n 1.7861208598377685,\n 1.8763420372585877,\n -0.3989792084778933,\n -0.7269652974563787,\n 0.630089647167973,\n -0.922198872166891,\n 3.726718379075423,\n 1.6835824388250755,\n 0.8576428268588719,\n 0.5880846882520954,\n 1.5488823262113791,\n 0.9312830994444764,\n 0.15213848556876752,\n 0.990237427747462,\n 0.9322305797207745,\n 3.3949423689917455,\n 0.25083434768314083,\n 1.480190006179775,\n -0.13194768394124462,\n 1.8360741255159232,\n 0.9754988456717159,\n 0.1777204530288133,\n 1.1746802548668027,\n 0.06091719007852282,\n 0.522024257876875,\n 2.7805540476056305,\n 0.4555427251566333,\n 0.8220596787045701,\n 0.561555240515752,\n ...]"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The standardized median income feature is: \")\n",
    "standard(new_df['median_income'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standardized new_feature income feature is: \n"
     ]
    },
    {
     "data": {
      "text/plain": "[nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n nan,\n ...]"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The standardized new_feature income feature is: \")\n",
    "standard(new_df['new_feature'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeroc\\AppData\\Local\\Temp\\ipykernel_20788\\48039691.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df[col] = standard(df[col])\n"
     ]
    }
   ],
   "source": [
    "for col in new_df.columns:\n",
    "    new_df[col] = standard(df[col])\n",
    "print(new_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[41. 21. 52. ... 17. 18. 16.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [105], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m scaler \u001B[38;5;241m=\u001B[39m preprocessing\u001B[38;5;241m.\u001B[39mStandardScaler()\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m#transform the feature\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[43mscaler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnew_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mhousing_median_age\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(x)\n",
      "File \u001B[1;32m~\\PycharmProjects\\Math\\venv\\lib\\site-packages\\sklearn\\base.py:867\u001B[0m, in \u001B[0;36mTransformerMixin.fit_transform\u001B[1;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[0;32m    863\u001B[0m \u001B[38;5;66;03m# non-optimized default implementation; override when a better\u001B[39;00m\n\u001B[0;32m    864\u001B[0m \u001B[38;5;66;03m# method is possible for a given clustering algorithm\u001B[39;00m\n\u001B[0;32m    865\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    866\u001B[0m     \u001B[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001B[39;00m\n\u001B[1;32m--> 867\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n\u001B[0;32m    868\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    869\u001B[0m     \u001B[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001B[39;00m\n\u001B[0;32m    870\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n",
      "File \u001B[1;32m~\\PycharmProjects\\Math\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:809\u001B[0m, in \u001B[0;36mStandardScaler.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    807\u001B[0m \u001B[38;5;66;03m# Reset internal state before fitting\u001B[39;00m\n\u001B[0;32m    808\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()\n\u001B[1;32m--> 809\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpartial_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Math\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:844\u001B[0m, in \u001B[0;36mStandardScaler.partial_fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    812\u001B[0m \u001B[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001B[39;00m\n\u001B[0;32m    813\u001B[0m \n\u001B[0;32m    814\u001B[0m \u001B[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    841\u001B[0m \u001B[38;5;124;03m    Fitted scaler.\u001B[39;00m\n\u001B[0;32m    842\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    843\u001B[0m first_call \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn_samples_seen_\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 844\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    845\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    846\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    847\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mFLOAT_DTYPES\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    848\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    849\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfirst_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    850\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    851\u001B[0m n_features \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    853\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\Math\\venv\\lib\\site-packages\\sklearn\\base.py:577\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    575\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mValidation should be done on X, y or both.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    576\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[1;32m--> 577\u001B[0m     X \u001B[38;5;241m=\u001B[39m check_array(X, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n\u001B[0;32m    578\u001B[0m     out \u001B[38;5;241m=\u001B[39m X\n\u001B[0;32m    579\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n",
      "File \u001B[1;32m~\\PycharmProjects\\Math\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    877\u001B[0m     \u001B[38;5;66;03m# If input is 1D raise error\u001B[39;00m\n\u001B[0;32m    878\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m array\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m--> 879\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    880\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected 2D array, got 1D array instead:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124marray=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    881\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    882\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myour data has a single feature or array.reshape(1, -1) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    883\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mif it contains a single sample.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(array)\n\u001B[0;32m    884\u001B[0m         )\n\u001B[0;32m    886\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype_numeric \u001B[38;5;129;01mand\u001B[39;00m array\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mkind \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUSV\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    887\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    888\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumeric\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is not compatible with arrays of bytes/strings.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    889\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConvert your data to numeric values explicitly instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    890\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Expected 2D array, got 1D array instead:\narray=[41. 21. 52. ... 17. 18. 16.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#standardize feature\n",
    "#create a scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "#transform the feature\n",
    "x = scaler.fit_transform(new_df['housing_median_age'])\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}